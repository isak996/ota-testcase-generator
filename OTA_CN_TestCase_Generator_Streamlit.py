
import io, re, random
import pandas as pd
import streamlit as st

st.set_page_config(page_title="èµ°æŸ¥è®°å½•ç”¨ä¾‹ç”Ÿæˆå™¨ï¼ˆä¸­æ–‡ï¼‰", layout="wide")
st.title("ğŸ§ª èµ°æŸ¥è®°å½•ç”¨ä¾‹ç”Ÿæˆå™¨ï¼ˆä¸­æ–‡ï¼‰")
st.caption("æŒ‰ã€æ¨¡æ¿ Ã— æ§½ä½ Ã— å™ªå£°/å£è¯­/æ–¹è¨€ Ã— ä¸Šä¸‹æ–‡ã€‘ç”Ÿæˆä¸­æ–‡ Queryï¼Œç›´æ¥å¯¹é½ä½ ä»¬çš„èµ°æŸ¥è®°å½•è¡¨å¤´ã€‚")

def list_slot(df, name):
    if df.empty: return []
    return df[df["slot"]==name]["value"].astype(str).tolist()

def replace_slots(tpl, pools):
    import re, random
    def repl(m):
        key = m.group(1)
        vals = pools.get(key, [])
        return random.choice(vals) if vals else "{" + key + "}"
    return re.sub(r"\{([a-zA-Z0-9_]+)\}", repl, str(tpl))

def build_noise_funcs(slots_df, typos_df):
    import random
    prefix = list_slot(slots_df, "prefix") or ["é‚£ä¸ªå•¥","æ‹œæ‰˜å•¦","éº»çƒ¦ä½ "]
    suffix = list_slot(slots_df, "suffix") or ["è°¢è°¢","è¾›è‹¦","å¤šè°¢"]
    particle = list_slot(slots_df, "particle") or ["å‘—","å•¦","å˜›"]
    dialect = list_slot(slots_df, "dialect") or ["æå¿«ç‚¹","å®‰é€¸","åšŸé¦–æ­Œ"]

    def w_typo(s: str) -> str:
        if typos_df is None or typos_df.empty: return s
        s2 = s
        for _, r in typos_df.sample(frac=1.0).iterrows():
            fr, to = str(r.get("from","")), str(r.get("to",""))
            if fr and fr in s2:
                s2 = s2.replace(fr, to, 1); break
        return s2

    def w_noise(s: str) -> str:
        t = s
        if random.random()<0.6: t = random.choice(prefix) + "â€¦" + t
        if random.random()<0.6: t = t + random.choice(particle)
        if random.random()<0.4: t = t + "ï¼Œ" + random.choice(suffix)
        return t

    def w_dialect(s: str) -> str:
        if random.random()<0.5:
            return s + "ï¼Œ" + random.choice(dialect)
        return s

    def w_long(s: str) -> str:
        filler = "æˆ‘åœ¨è·¯ä¸Šæœ‰ç‚¹å µå¿ƒæƒ…ä¹Ÿä¸€èˆ¬ï¼Œä¸è¿‡è¿˜æƒ³å¬ç‚¹æ”¾æ¾çš„ï¼Œ"
        return filler + s + "ï¼Œå¦‚æœä¸è¡Œä¹Ÿæ²¡å…³ç³»ä½ çœ‹ç€åŠå§"
    return w_typo, w_noise, w_dialect, w_long

def to_excel_bytes(df):
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as w:
        df.to_excel(w, index=False)
    return buf.getvalue()

with st.sidebar:
    st.header("âš™ï¸ ç”Ÿæˆé…ç½®")
    seed = st.number_input("éšæœºç§å­", value=42, min_value=0, step=1)
    per_template_samples = st.number_input("æ¯ä¸ªæ¨¡æ¿é‡‡æ ·æ•°", value=300, min_value=0, step=50)
    max_cases_per_intent = st.number_input("æ¯ä¸ªæ„å›¾æœ€å¤§æ¡æ•°", value=4000, min_value=100, step=100)
    max_total_cases = st.number_input("å…¨å±€æœ€å¤§æ¡æ•°", value=20000, min_value=1000, step=1000)
    augment_base = st.checkbox("å¯¹åŸºç¡€çŸ­å¥ä¹ŸåŠ å£è¯­/é”™å†™/å†—ä½™", value=True)
    st.markdown("---")
    st.subheader("ğŸ“¤ ä¸Šä¼ åº“å­˜ Excelï¼ˆå¯é€‰ï¼‰")
    st.caption("éœ€è¦åŒ…å« sheetsï¼šintents / templates / slots / noise_typo / contexts")
    inv = st.file_uploader("ä¸Šä¼  .xlsx", type=["xlsx"])

import random
random.seed(42)

def default_inventory():
    intents = pd.DataFrame([
        {"intent_id":"æ’­æ”¾_éŸ³ä¹","action":"æ’­æ”¾åª’ä½“","base_phrases":"æ’­æ”¾éŸ³ä¹;æ”¾ä¸€é¦–æ­Œ;æ¥ç‚¹éŸ³ä¹","synonyms":"æ¥é¦–å—¨æ­Œ;æ”¾ä¸ªç²¤è¯­æ­Œå¬å¬"},
        {"intent_id":"å¯¼èˆª_POI","action":"å¯¼èˆª","base_phrases":"å¸¦æˆ‘å»{poi}ï¼Œåœ¨{city}","synonyms":"å»{city}çš„{poi}"},
        {"intent_id":"è½¦æ§_ç©ºè°ƒ_è®¾å®šæ¸©åº¦","action":"è½¦æ§","base_phrases":"æŠŠæ¸©åº¦è®¾åˆ°{temp}åº¦","synonyms":"ç©ºè°ƒè°ƒåˆ°{temp}Â°"},
        {"intent_id":"ä¸æ”¯æŒ","action":"ä¸æ”¯æŒ","base_phrases":"å¸®æˆ‘ç‚¹ä¸ªå¤–å–","synonyms":"ä¹°æ¯å¥¶èŒ¶"},
        {"intent_id":"æ‹’ç­”","action":"å®‰å…¨æ‹¦æˆª","base_phrases":"æ¶‰é»„å†…å®¹","synonyms":"è¾±éª‚è¯­"},
    ])
    templates = pd.DataFrame([
        {"intent_id":"æ’­æ”¾_éŸ³ä¹","template":"æ”¾ä¸€é¦–{artist}çš„æ­Œ","test_type":"åŸºç¡€","note":"è‰ºäººå"},
        {"intent_id":"æ’­æ”¾_éŸ³ä¹","template":"æ¥ç‚¹{genre}é£æ ¼çš„éŸ³ä¹","test_type":"æ¨¡ç³Š/å™ªå£°","note":"æ›²é£"},
        {"intent_id":"å¯¼èˆª_POI","template":"å¸¦æˆ‘å»{poi}ï¼Œåœ¨{city}","test_type":"åŸºç¡€","note":""},
        {"intent_id":"è½¦æ§_ç©ºè°ƒ_è®¾å®šæ¸©åº¦","template":"ç©ºè°ƒè°ƒåˆ°{temp}Â°","test_type":"åŸºç¡€","note":""},
    ])
    slots = pd.DataFrame([
        {"slot":"artist","value":"å‘¨æ°ä¼¦"},{"slot":"artist","value":"æ—ä¿Šæ°"},{"slot":"artist","value":"ç‹è²"},
        {"slot":"genre","value":"æ°‘è°£"},{"slot":"genre","value":"R&B"},{"slot":"genre","value":"æ‘‡æ»š"},
        {"slot":"poi","value":"åŒ»é™¢"},{"slot":"poi","value":"åŠ æ²¹ç«™"},{"slot":"poi","value":"åœè½¦åœº"},
        {"slot":"city","value":"ä¸Šæµ·"},{"slot":"city","value":"åŒ—äº¬"},{"slot":"city","value":"å¹¿å·"},
        {"slot":"temp","value":"18"},{"slot":"temp","value":"22"},{"slot":"temp","value":"26"},
        {"slot":"prefix","value":"é‚£ä¸ªå•¥"},{"slot":"prefix","value":"æ‹œæ‰˜å•¦"},{"slot":"prefix","value":"éº»çƒ¦ä½ "},
        {"slot":"suffix","value":"è°¢è°¢"},{"slot":"suffix","value":"è¾›è‹¦"},{"slot":"suffix","value":"å¤šè°¢"},
        {"slot":"particle","value":"å‘—"},{"slot":"particle","value":"å•¦"},{"slot":"particle","value":"å˜›"},
        {"slot":"dialect","value":"æå¿«ç‚¹"},{"slot":"dialect","value":"å®‰é€¸"},{"slot":"dialect","value":"åšŸé¦–æ­Œ"},
    ])
    noise_typo = pd.DataFrame([
        {"from":"éŸ³ä¹","to":"éŸ³æ¨‚"},{"from":"éŸ³ä¹","to":"éŸ³ç¥"},{"from":"æ’­æ”¾","to":"æ’­æ–¹"},
    ])
    contexts = pd.DataFrame([
        {"group_id":"G_å¤šè½®_æ¢æ­Œ","step":1,"query":"æ”¾{artist}çš„æ­Œ","expected_intent":"æ’­æ”¾_éŸ³ä¹","note":""},
        {"group_id":"G_å¤šè½®_æ¢æ­Œ","step":2,"query":"æ¢æˆ{artist}çš„","expected_intent":"æ’­æ”¾_éŸ³ä¹","note":"ä¸Šä¸‹æ–‡å»¶ç»­"},
    ])
    return intents, templates, slots, noise_typo, contexts

if inv:
    xls = pd.ExcelFile(inv)
    def read_sheet(name): return pd.read_excel(xls, name) if name in xls.sheet_names else pd.DataFrame()
    intents_df   = read_sheet("intents")
    templates_df = read_sheet("templates")
    slots_df     = read_sheet("slots")
    noise_df     = read_sheet("noise_typo")
    contexts_df  = read_sheet("contexts")
    if any(df.empty for df in [intents_df, templates_df]):
        st.warning("intents/templates ä¸èƒ½ä¸ºç©ºï¼Œå·²å›é€€åˆ°é»˜è®¤ç¤ºä¾‹ã€‚")
        intents_df, templates_df, slots_df, noise_df, contexts_df = default_inventory()
else:
    intents_df, templates_df, slots_df, noise_df, contexts_df = default_inventory()

st.markdown("### ğŸ“š æ„å›¾ï¼ˆintentsï¼‰")
st.dataframe(intents_df, use_container_width=True, height=220)
st.markdown("### ğŸ§© æ¨¡æ¿ï¼ˆtemplatesï¼‰")
st.dataframe(templates_df, use_container_width=True, height=220)
st.markdown("### ğŸ§° æ§½ä½ï¼ˆslotsï¼‰")
st.dataframe(slots_df, use_container_width=True, height=220)

with st.expander("ğŸª› é”™å†™/æ‰°åŠ¨ï¼ˆnoise_typoï¼‰", expanded=False):
    st.dataframe(noise_df, use_container_width=True)
with st.expander("ğŸ—£ï¸ ä¸Šä¸‹æ–‡ï¼ˆcontextsï¼‰", expanded=False):
    st.dataframe(contexts_df, use_container_width=True)

st.markdown("---")
if st.button("â–¶ï¸ ä¸€é”®ç”Ÿæˆä¸­æ–‡ç”¨ä¾‹"):
    pools = {s: slots_df[slots_df["slot"]==s]["value"].astype(str).tolist() for s in slots_df["slot"].unique()}
    w_typo, w_noise, w_dialect, w_long = build_noise_funcs(slots_df, noise_df)

    rows = []
    def push(q, intent, action, ttype, diff=1, group="", ctx="", note=""):
        rows.append({
            "Queryæ–‡æœ¬": q, "é¢„æœŸæ„å›¾": intent, "é¢„æœŸåŠ¨ä½œ": action or "",
            "æµ‹è¯•ç±»å‹": ttype, "éš¾åº¦ç­‰çº§": diff, "åˆ†ç»„": group, "ä¸Šä¸‹æ–‡": ctx, "å¤‡æ³¨": note
        })

    # åŸºç¡€ä¸åŒä¹‰
    for _, r in intents_df.iterrows():
        intent = str(r.get("intent_id","")).strip()
        if not intent: continue
        action = str(r.get("action","")).strip()
        base = [x for x in re.split(r"[;ï¼›]", str(r.get("base_phrases",""))) if x.strip()]
        syns = [x for x in re.split(r"[;ï¼›]", str(r.get("synonyms",""))) if x.strip()]
        gb, gs = f"G_{intent}_B", f"G_{intent}_S"
        for q in base[:5]:
            q2 = replace_slots(q, pools)
            push(q2, intent, action, "åŸºç¡€", 1, gb)
            push(w_typo(q2), intent, action, "æ¨¡ç³Š/å™ªå£°", 2, f"G_{intent}_N", "", "é”™å†™/ç¹ç®€")
            push(w_noise(q2), intent, action, "æ¨¡ç³Š/å™ªå£°", 2, f"G_{intent}_N", "", "å™ªå£°å†—ä½™")
            push(w_dialect(q2), intent, action, "æ¨¡ç³Š/å™ªå£°", 2, f"G_{intent}_N", "", "æ–¹è¨€å£è¯­")
        for q in syns[:5]:
            q2 = replace_slots(q, pools)
            push(q2, intent, action, "åŸºç¡€", 2, gs, "", "åŒä¹‰æ›¿æ¢")

    # æ¨¡æ¿é‡‡æ ·ï¼ˆæµ·é‡ï¼‰
    per_tpl = 300
    max_intent = 4000
    max_total  = 20000
    tpl_grouped = templates_df.groupby("intent_id")
    count_per_intent = {}

    for intent, grp in tpl_grouped:
        action = intents_df.loc[intents_df["intent_id"]==intent, "action"]
        action = action.iloc[0] if len(action)>0 else ""
        group_t = f"G_{intent}_TPL"
        tpls = grp[["template","test_type","note"]].values.tolist()
        samples = 0
        while count_per_intent.get(intent,0) < max_intent and samples < per_tpl*max(1,len(tpls)):
            tpl, ttype, note = random.choice(tpls)
            q = replace_slots(tpl, pools)
            push(q, intent, action, ttype or "åŸºç¡€", 1 if (ttype or "")=="åŸºç¡€" else 2, group_t, "", note or "")
            count_per_intent[intent] = count_per_intent.get(intent,0)+1
            samples += 1
            if len(rows) >= max_total: break
        if len(rows) >= max_total: break

    # ä¸Šä¸‹æ–‡/å¤šè½®
    for gid, grp in contexts_df.groupby("group_id"):
        prev = ""
        grp = grp.sort_values("step") if "step" in grp.columns else grp
        for _, r in grp.iterrows():
            q = replace_slots(r.get("query",""), pools)
            intent = str(r.get("expected_intent","")).strip()
            push(q, intent, "", "ä¸Šä¸‹æ–‡", 2, str(gid), prev, str(r.get("note","")))
            prev = f"ä¸Šä¸€å¥ï¼š{q}"

    df = pd.DataFrame(rows).drop_duplicates(subset=["Queryæ–‡æœ¬","é¢„æœŸæ„å›¾","æµ‹è¯•ç±»å‹","ä¸Šä¸‹æ–‡"]).reset_index(drop=True)
    st.success(f"å·²ç”Ÿæˆ {len(df)} æ¡ä¸­æ–‡ç”¨ä¾‹")
    st.dataframe(df.head(50), use_container_width=True)

    csv = df.to_csv(index=False).encode("utf-8-sig")
    xlsx = to_excel_bytes(df)
    st.download_button("â¬‡ï¸ ä¸‹è½½ CSVï¼ˆUTF-8ï¼‰", data=csv, file_name="test_cases_cn.csv", mime="text/csv")
    st.download_button("â¬‡ï¸ ä¸‹è½½ Excelï¼ˆxlsxï¼‰", data=xlsx, file_name="test_cases_cn.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
